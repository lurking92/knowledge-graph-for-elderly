{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lurking92/knowledge-graph-for-elderly/blob/main/BLIP_%E9%96%8B%E7%99%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3c9f9",
   "metadata": {
    "id": "18f3c9f9"
   },
   "source": [
    "# 增強版影片分析（Colab 版 .ipynb）\n",
    "本 Notebook 在 Google Colab 上可直接執行，完成以下工作：\n",
    "- 安裝相依套件並建立專案目錄\n",
    "- 自動下載 Grounding DINO 所需權重\n",
    "- 影片上傳到 `data/videos/`\n",
    "- 以 `scripts/` 拆分模組：`extract_frames.py`、`object_detector.py`、`generate_caption.py`\n",
    "- 透過 `main.py` 串起整個流程，輸出字幕與偵測摘要\n",
    "\n",
    "執行順序：依序執行每個區塊即可；最後用 `!python main.py --video ...` 或 `--dir ...` 執行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d5985",
   "metadata": {
    "id": "0e2d5985"
   },
   "source": [
    "## 函式庫安裝與設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d4e64f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6d4e64f",
    "outputId": "111f66ff-2d33-4924-c105-f0c98f0a13f1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "opencc-python-reimplemented\n",
    "opencv-python-headless>=4.10.0.84\n",
    "torch\n",
    "torchvision\n",
    "transformers>=4.41.0\n",
    "tokenizers>=0.20.0\n",
    "accelerate>=0.24.1\n",
    "Pillow>=10.0.0\n",
    "tqdm\n",
    "ffmpeg-python\n",
    "sentencepiece\n",
    "sacremoses\n",
    "scipy>=1.14.0\n",
    "numpy>=1.26.4,<2.0\n",
    "einops\n",
    "requests\n",
    "timm>=0.9.16\n",
    "protobuf>=4.25.3,<5\n",
    "matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77bcc6d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77bcc6d9",
    "outputId": "2a0eff74-344d-415b-cff2-648d2511ecd6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m函式庫安裝完成。\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt\n",
    "print(\"函式庫安裝完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddeb170",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ddeb170",
    "outputId": "19db65f6-3889-4b6a-c4b5-a9dd7ef4ed23"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "目錄準備完成。\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path('/content')\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "VIDEO_DIR = DATA_DIR / 'videos'\n",
    "FRAME_DIR = DATA_DIR / 'frames'\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "MODELS_DIR = Path('models')\n",
    "SCRIPTS_DIR = Path('scripts')\n",
    "\n",
    "for folder in [DATA_DIR, VIDEO_DIR, FRAME_DIR, OUTPUT_DIR, MODELS_DIR, SCRIPTS_DIR]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "print('目錄準備完成。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d98d2f",
   "metadata": {
    "id": "32d98d2f"
   },
   "source": [
    "## 模型下載與設定（Grounding DINO）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b65526e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b65526e",
    "outputId": "67db88e4-b927-4469-b3c2-6bcdcf82818c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GroundingDINO_SwinT_OGC.py: 1.01kB [00:00, 1.65MB/s]                 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "已下載 GroundingDINO_SwinT_OGC.py\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "groundingdino_swint_ogc.pth: 100%|██████████| 694M/694M [00:13<00:00, 52.3MB/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "已下載 groundingdino_swint_ogc.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "GROUNDING_DINO_CONFIG_URL = 'https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
    "GROUNDING_DINO_WEIGHTS_URL = 'https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth'\n",
    "\n",
    "config_path = Path('models/GroundingDINO_SwinT_OGC.py')\n",
    "weights_path = Path('models/groundingdino_swint_ogc.pth')\n",
    "\n",
    "def download_file(url: str, destination: Path) -> None:\n",
    "    if destination.exists():\n",
    "        print(f'{destination.name} 已存在，略過下載。')\n",
    "        return\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    total = int(response.headers.get('content-length', 0))\n",
    "    progress = tqdm(total=total, unit='B', unit_scale=True, desc=destination.name)\n",
    "    with destination.open('wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                progress.update(len(chunk))\n",
    "    progress.close()\n",
    "    print(f'已下載 {destination.name}')\n",
    "\n",
    "download_file(GROUNDING_DINO_CONFIG_URL, config_path)\n",
    "download_file(GROUNDING_DINO_WEIGHTS_URL, weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc1fed",
   "metadata": {
    "id": "7ccc1fed"
   },
   "source": [
    "### 選用：掛載 Google Drive（若影片放在雲端硬碟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae6effd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ae6effd",
    "outputId": "72411f93-84d4-4622-de54-da9fbe9aeab1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# 如需使用 Google Drive 檔案請執行，否則可略過\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4421a",
   "metadata": {
    "id": "e0e4421a"
   },
   "source": [
    "### 選用：Hugging Face 登入（若需存取 gated 模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66306c2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66306c2b",
    "outputId": "74437792-6355-4a00-b933-b311d1070d13"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hugging Face 登入成功\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "try:\n",
    "    # Colab 的使用者可於右上角「變數」區設定 HF_TOKEN\n",
    "    from google.colab import userdata\n",
    "    token = userdata.get('HF_TOKEN')\n",
    "except Exception:\n",
    "    token = None\n",
    "\n",
    "if token:\n",
    "    login(token)\n",
    "    print(\"Hugging Face 登入成功\")\n",
    "else:\n",
    "    print(\"未提供 HF_TOKEN，若模型需要授權請手動登入或設定變數。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab785b",
   "metadata": {
    "id": "bbab785b"
   },
   "source": [
    "## 上傳測試影片到 `data/videos/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d1f9f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "91d1f9f4",
    "outputId": "73975c39-ac47-46f5-ef5a-6b27fafa0cc5"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-73b1c88a-2621-4826-b48d-11723a19b716\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-73b1c88a-2621-4826-b48d-11723a19b716\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving Cook carrot1_1.mp4 to Cook carrot1_1.mp4\n",
      "Saving Cook fried bread4_1.mp4 to Cook fried bread4_1.mp4\n",
      "Saving Cook potato using microwave1_4.mp4 to Cook potato using microwave1_4.mp4\n",
      "影片已上傳到: ['/content/data/videos/Cook carrot1_1.mp4', '/content/data/videos/Cook fried bread4_1.mp4', '/content/data/videos/Cook potato using microwave1_4.mp4']\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "uploaded = files.upload()\n",
    "video_paths = []\n",
    "for fname in uploaded.keys():\n",
    "    dst = VIDEO_DIR / fname\n",
    "    shutil.move(fname, dst)\n",
    "    video_paths.append(str(dst))\n",
    "print('影片已上傳到:', video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2d3a4",
   "metadata": {
    "id": "2ba2d3a4"
   },
   "source": [
    "## 影格提取模組：`scripts/extract_frames.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c101c242",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c101c242",
    "outputId": "eef49f3e-5328-4ef7-e567-c1dc2b5eab65"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/extract_frames.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/extract_frames.py\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import cv2\n",
    "\n",
    "def extract_frames(video_path: str, output_dir: str, target_fps: float = 1.0) -> Tuple[List[Tuple[str, float]], float]:\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f'無法開啟影片: {video_path}')\n",
    "\n",
    "    native_fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    step = max(int(round(native_fps / max(target_fps, 1e-3))), 1)\n",
    "\n",
    "    frame_idx = 0\n",
    "    saved: List[Tuple[str, float]] = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % step == 0:\n",
    "            timestamp = frame_idx / native_fps\n",
    "            frame_name = f'frame_{frame_idx:06d}.jpg'\n",
    "            frame_path = os.path.join(output_dir, frame_name)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            saved.append((frame_path, timestamp))\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f'已提取 {len(saved)} 個影格，原始FPS: {native_fps:.2f}')\n",
    "    return saved, native_fps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2ed66",
   "metadata": {
    "id": "45d2ed66"
   },
   "source": [
    "## 物件偵測模組：`scripts/object_detector.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4101731b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4101731b",
    "outputId": "e31c487b-efe1-474e-ce3b-7ef370be242e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/object_detector.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/object_detector.py\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "\n",
    "from scripts.utils import normalize_label\n",
    "\n",
    "DEFAULT_PROMPT = (\n",
    "    'person, man, woman, child, elderly, baby, '\n",
    "    'bed, pillow, blanket, sheet, mattress, nightstand, bedside table, '\n",
    "    'lamp, desk lamp, floor lamp, ceiling light, '\n",
    "    'sofa, couch, armchair, chair, dining chair, office chair, '\n",
    "    'table, dining table, coffee table, desk, '\n",
    "    'television, tv, monitor, computer, laptop, '\n",
    "    'stove, oven, refrigerator, fridge, microwave, '\n",
    "    'sink, faucet, cabinet, cupboard, drawer, '\n",
    "    'pan, pot, bowl, cup, plate, knife, fork, spoon, '\n",
    "    'toilet, bathtub, shower, mirror, towel, '\n",
    "    'door, window, curtain, blind, '\n",
    "    'carpet, rug, floor, wall, ceiling, '\n",
    "    'plant, flower, book, clock, picture, painting'\n",
    ")\n",
    "\n",
    "_processor: Optional[AutoProcessor] = None\n",
    "_model: Optional[AutoModelForZeroShotObjectDetection] = None\n",
    "_device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def setup_grounding_dino() -> None:\n",
    "    \"\"\"初始化 Grounding DINO 模型\"\"\"\n",
    "    global _processor, _model\n",
    "    if _processor is not None and _model is not None:\n",
    "        print('Grounding DINO 模型已載入')\n",
    "        return\n",
    "\n",
    "    print('正在載入 Grounding DINO 模型...')\n",
    "    model_name = \"IDEA-Research/grounding-dino-tiny\"\n",
    "    _processor = AutoProcessor.from_pretrained(model_name)\n",
    "    _model = AutoModelForZeroShotObjectDetection.from_pretrained(model_name)\n",
    "    _model.to(_device)\n",
    "    print(f'Grounding DINO 模型已載入至 {_device}')\n",
    "\n",
    "def detect_objects(\n",
    "    image_path: str,\n",
    "    text_prompt: str = DEFAULT_PROMPT,\n",
    "    box_threshold: float = 0.25,\n",
    "    top_k: int = 15,\n",
    "    visualize: bool = False\n",
    ") -> Tuple[List[Dict], Optional[Image.Image]]:\n",
    "    \"\"\"使用 Grounding DINO 進行物件偵測\"\"\"\n",
    "    if _processor is None or _model is None:\n",
    "        raise RuntimeError('請先呼叫 setup_grounding_dino() 載入模型。')\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = _processor(images=image, text=text_prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(_device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = _model(**inputs)\n",
    "\n",
    "    target_sizes = torch.tensor([image.size[::-1]]).to(_device)\n",
    "    results = _processor.post_process_grounded_object_detection(\n",
    "        outputs, target_sizes=target_sizes, threshold=box_threshold\n",
    "    )[0]\n",
    "\n",
    "    detections: List[Dict] = []\n",
    "    if 'boxes' in results:\n",
    "        boxes = results['boxes'].cpu()\n",
    "        scores = results['scores'].cpu()\n",
    "        labels = results['labels']\n",
    "\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            raw_label = str(label).lower().strip()\n",
    "            canonical = normalize_label(raw_label)\n",
    "            if not canonical:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            detections.append({\n",
    "                'label': canonical,\n",
    "                'raw_label': raw_label,\n",
    "                'score': float(score),\n",
    "                'bbox_xyxy': [x1, y1, x2, y2],\n",
    "                'area': (x2 - x1) * (y2 - y1)\n",
    "            })\n",
    "\n",
    "    detections = sorted(detections, key=lambda d: d['score'], reverse=True)[:top_k]\n",
    "\n",
    "    annotated_image = None\n",
    "    if visualize and detections:\n",
    "        annotated_image = create_detection_visualization(image, detections)\n",
    "\n",
    "    return detections, annotated_image\n",
    "\n",
    "def create_detection_visualization(image: Image.Image, detections: List[Dict]) -> Image.Image:\n",
    "    vis_image = image.copy()\n",
    "    draw = ImageDraw.Draw(vis_image)\n",
    "\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 16)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i, detection in enumerate(detections[:10]):\n",
    "        x1, y1, x2, y2 = detection['bbox_xyxy']\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
    "\n",
    "        label_text = f\"{detection.get('raw_label', detection['label'])} ({detection['score']:.2f})\"\n",
    "        text_bbox = draw.textbbox((x1, y1 - 25), label_text, font=font)\n",
    "        draw.rectangle(text_bbox, fill=color)\n",
    "        draw.text((x1, y1 - 25), label_text, fill='white', font=font)\n",
    "\n",
    "    return vis_image\n",
    "\n",
    "def summarize_detections(detections: List[Dict], top_k: int = 8) -> str:\n",
    "    if not detections:\n",
    "        return '未偵測到重點物件'\n",
    "\n",
    "    unique: Dict[str, Dict] = {}\n",
    "    for det in detections:\n",
    "        label_key = det.get('label') or normalize_label(det.get('raw_label', ''))\n",
    "        if not label_key:\n",
    "            continue\n",
    "        if label_key not in unique or det['score'] > unique[label_key]['score']:\n",
    "            unique[label_key] = det\n",
    "\n",
    "    sorted_dets = sorted(unique.values(), key=lambda d: d['score'], reverse=True)\n",
    "    items = [f\"{d['label']}({d['score']:.2f})\" for d in sorted_dets[:top_k]]\n",
    "    return ', '.join(items)\n",
    "\n",
    "def analyze_scene_context(detections: List[Dict]) -> Dict[str, any]:\n",
    "    context = {\n",
    "        'person_count': 0,\n",
    "        'furniture_items': [],\n",
    "        'appliances': [],\n",
    "        'room_indicators': [],\n",
    "        'dominant_objects': []\n",
    "    }\n",
    "\n",
    "    for det in detections:\n",
    "        raw_label = det.get('raw_label', det.get('label', ''))\n",
    "        label = raw_label.lower()\n",
    "        score = det['score']\n",
    "\n",
    "        if any(person_word in label for person_word in ['person', 'man', 'woman', 'child', 'people', 'elderly', 'baby']):\n",
    "            context['person_count'] += 1\n",
    "\n",
    "        furniture_keywords = ['sofa', 'chair', 'table', 'bed', 'desk', 'cabinet', 'couch', 'nightstand']\n",
    "        if any(keyword in label for keyword in furniture_keywords):\n",
    "            context['furniture_items'].append((det.get('label', label), score))\n",
    "\n",
    "        appliance_keywords = ['tv', 'television', 'refrigerator', 'microwave', 'oven', 'stove', 'washer', 'dryer']\n",
    "        if any(keyword in label for keyword in appliance_keywords):\n",
    "            context['appliances'].append((det.get('label', label), score))\n",
    "\n",
    "        if score > 0.3:\n",
    "            context['room_indicators'].append((det.get('label', label), score))\n",
    "\n",
    "    for det in detections[:5]:\n",
    "        if det['score'] > 0.4 and det.get('area', 0) > 1000:\n",
    "            context['dominant_objects'].append((det.get('label'), det['score']))\n",
    "\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad966a",
   "metadata": {
    "id": "9fad966a"
   },
   "source": [
    "## 文字敘述模組：`scripts/generate_caption.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26e938c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26e938c6",
    "outputId": "26217bf9-6056-475e-ec92-0c4a6931b469"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/generate_caption.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/generate_caption.py\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline\n",
    "from opencc import OpenCC\n",
    "\n",
    "# 全局變數\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "_blip_processor = None\n",
    "_blip_model = None\n",
    "_translator = None\n",
    "_converter = None\n",
    "\n",
    "def initialize_models():\n",
    "    \"\"\"初始化所有必要的模型\"\"\"\n",
    "    global _blip_processor, _blip_model, _translator, _converter\n",
    "\n",
    "    if _blip_processor is None:\n",
    "        print('正在載入 BLIP 模型...')\n",
    "        _blip_processor = BlipProcessor.from_pretrained('Salesforce/blip-image-captioning-large')\n",
    "        _blip_model = BlipForConditionalGeneration.from_pretrained('Salesforce/blip-image-captioning-large').to(DEVICE)\n",
    "        print(f'BLIP 模型已載入至 {DEVICE}')\n",
    "\n",
    "    if _translator is None:\n",
    "        print('正在載入翻譯模型...')\n",
    "        _translator = pipeline('translation', model='Helsinki-NLP/opus-mt-en-zh', device=0 if torch.cuda.is_available() else -1)\n",
    "        print('翻譯模型已載入')\n",
    "\n",
    "    if _converter is None:\n",
    "        _converter = OpenCC('s2t')\n",
    "\n",
    "# 物件中英對照表\n",
    "OBJECT_TRANSLATIONS = {\n",
    "    'person': '人物', 'people': '多人', 'man': '男性', 'woman': '女性', 'child': '兒童', 'baby': '嬰兒',\n",
    "    'bed': '床鋪', 'pillow': '枕頭', 'blanket': '毛毯', 'sheet': '床單', 'mattress': '床墊',\n",
    "    'nightstand': '床頭櫃', 'bedside table': '床邊桌',\n",
    "    'lamp': '檯燈', 'desk lamp': '桌燈', 'floor lamp': '立燈', 'ceiling light': '天花板燈',\n",
    "    'sofa': '沙發', 'couch': '沙發', 'armchair': '扶手椅', 'chair': '椅子',\n",
    "    'dining chair': '餐椅', 'office chair': '辦公椅',\n",
    "    'table': '桌子', 'dining table': '餐桌', 'coffee table': '茶几', 'desk': '書桌',\n",
    "    'television': '電視', 'tv': '電視', 'monitor': '螢幕', 'computer': '電腦', 'laptop': '筆電',\n",
    "    'stove': '爐子', 'oven': '烤箱', 'refrigerator': '冰箱', 'fridge': '冰箱', 'microwave': '微波爐',\n",
    "    'sink': '水槽', 'faucet': '水龍頭', 'cabinet': '櫥櫃', 'cupboard': '櫃子', 'drawer': '抽屜',\n",
    "    'pan': '平底鍋', 'pot': '湯鍋', 'bowl': '碗', 'cup': '杯子', 'plate': '盤子',\n",
    "    'knife': '刀具', 'fork': '叉子', 'spoon': '湯匙',\n",
    "    'toilet': '馬桶', 'bathtub': '浴缸', 'shower': '淋浴設備', 'mirror': '鏡子', 'towel': '毛巾',\n",
    "    'door': '門', 'window': '窗戶', 'curtain': '窗簾', 'blind': '百葉窗',\n",
    "    'carpet': '地毯', 'rug': '地墊', 'floor': '地板', 'wall': '牆壁', 'ceiling': '天花板',\n",
    "    'plant': '植物', 'flower': '花朵', 'book': '書籍', 'clock': '時鐘', 'picture': '圖畫', 'painting': '畫作'\n",
    "}\n",
    "\n",
    "# 房間關鍵物件映射\n",
    "ROOM_KEYWORDS = {\n",
    "    '臥室': {'bed', 'pillow', 'blanket', 'nightstand', 'bedside table', 'mattress', 'sheet'},\n",
    "    '廚房': {'stove', 'oven', 'refrigerator', 'fridge', 'microwave', 'sink', 'cabinet', 'pan', 'pot', 'bowl', 'cup', 'plate'},\n",
    "    '廁所': {'toilet', 'bathtub', 'shower', 'sink', 'mirror', 'towel', 'faucet'},\n",
    "    '客廳': {'sofa', 'couch', 'television', 'tv', 'coffee table', 'armchair', 'carpet', 'rug'}\n",
    "}\n",
    "\n",
    "# 環境描述模板\n",
    "ENVIRONMENT_TEMPLATES = {\n",
    "    '臥室': ['溫馨的睡眠空間', '私人休息區域', '舒適的臥房環境'],\n",
    "    '廚房': ['烹飪與用餐空間', '家庭料理區域', '廚房工作環境'],\n",
    "    '廁所': ['衛浴清潔空間', '個人盥洗區域', '浴室環境'],\n",
    "    '客廳': ['家庭聚會空間', '休閒娛樂區域', '客廳起居環境']\n",
    "}\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_base_caption(image_path: str, prompt: str = None) -> str:\n",
    "    \"\"\"使用 BLIP 生成基礎英文描述\"\"\"\n",
    "    if _blip_processor is None or _blip_model is None:\n",
    "        raise RuntimeError('請先呼叫 initialize_models() 載入模型')\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    if prompt is None:\n",
    "        prompt = \"Describe this scene in detail, including the people, objects, activities, and environment.\"\n",
    "\n",
    "    inputs = _blip_processor(images=image, text=prompt, return_tensors='pt').to(DEVICE)\n",
    "\n",
    "    output = _blip_model.generate(\n",
    "        **inputs,\n",
    "        max_length=120,\n",
    "        num_beams=8,\n",
    "        no_repeat_ngram_size=3,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        length_penalty=1.2\n",
    "    )\n",
    "\n",
    "    caption = _blip_processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    if prompt and caption.startswith(prompt):\n",
    "        caption = caption[len(prompt):].strip()\n",
    "\n",
    "    return caption\n",
    "\n",
    "def translate_to_traditional_chinese(text: str) -> str:\n",
    "    \"\"\"將英文翻譯為繁體中文\"\"\"\n",
    "    if _translator is None or _converter is None:\n",
    "        raise RuntimeError('請先呼叫 initialize_models() 載入模型')\n",
    "\n",
    "    try:\n",
    "        sentences = text.split('. ')\n",
    "        translated_sentences = []\n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():\n",
    "                result = _translator(sentence.strip())[0]['translation_text']\n",
    "                translated_sentences.append(result)\n",
    "        translated_text = '。'.join(translated_sentences)\n",
    "        if not translated_text.endswith('。'):\n",
    "            translated_text += '。'\n",
    "        return _converter.convert(translated_text)\n",
    "    except Exception as e:\n",
    "        print(f'翻譯過程中出現錯誤: {e}')\n",
    "        return '無法生成中文描述。'\n",
    "\n",
    "def infer_room_from_detections(detections: List[Dict]) -> Optional[str]:\n",
    "    \"\"\"從偵測結果推斷房間類型\"\"\"\n",
    "    if not detections:\n",
    "        return None\n",
    "    labels = {d['label'].lower() for d in detections if d['score'] > 0.3}\n",
    "    room_scores = {}\n",
    "    for room, keywords in ROOM_KEYWORDS.items():\n",
    "        score = len(labels & keywords)\n",
    "        if score > 0:\n",
    "            room_scores[room] = score\n",
    "    if room_scores:\n",
    "        return max(room_scores, key=room_scores.get)\n",
    "    return None\n",
    "\n",
    "def create_object_description(detections: List[Dict], max_objects: int = 10) -> str:\n",
    "    \"\"\"創建詳細的物件描述\"\"\"\n",
    "    if not detections:\n",
    "        return \"\"\n",
    "    people, furniture, appliances, other_objects = [], [], [], []\n",
    "    for det in detections[:max_objects]:\n",
    "        label = det['label'].lower()\n",
    "        score = det['score']\n",
    "        zh_label = OBJECT_TRANSLATIONS.get(label, label)\n",
    "        obj_desc = f\"{zh_label}(信心度{score:.2f})\"\n",
    "        if any(w in label for w in ['person', 'man', 'woman', 'child', 'people', 'baby']):\n",
    "            people.append(obj_desc)\n",
    "        elif any(w in label for w in ['sofa', 'chair', 'table', 'bed', 'desk', 'cabinet']):\n",
    "            furniture.append(obj_desc)\n",
    "        elif any(w in label for w in ['tv', 'television', 'refrigerator', 'microwave', 'oven', 'stove']):\n",
    "            appliances.append(obj_desc)\n",
    "        else:\n",
    "            other_objects.append(obj_desc)\n",
    "    descriptions = []\n",
    "    if people:\n",
    "        descriptions.append(f\"人物：{', '.join(people)}\")\n",
    "    if furniture:\n",
    "        descriptions.append(f\"家具：{', '.join(furniture[:5])}\")\n",
    "    if appliances:\n",
    "        descriptions.append(f\"電器：{', '.join(appliances[:3])}\")\n",
    "    if other_objects:\n",
    "        descriptions.append(f\"其他物件：{', '.join(other_objects[:5])}\")\n",
    "    return '；'.join(descriptions) + '。' if descriptions else \"\"\n",
    "\n",
    "def analyze_spatial_relationships(detections: List[Dict]) -> str:\n",
    "    \"\"\"分析空間關係\"\"\"\n",
    "    if len(detections) < 2:\n",
    "        return \"\"\n",
    "    relationships = []\n",
    "    people = [d for d in detections if any(w in d['label'].lower() for w in ['person', 'man', 'woman', 'child'])]\n",
    "    furniture = [d for d in detections if any(w in d['label'].lower() for w in ['sofa', 'chair', 'bed', 'table'])]\n",
    "    if people and furniture:\n",
    "        relationships.append(\"場景中有人物與家具的互動配置\")\n",
    "    if len(detections) > 8:\n",
    "        relationships.append(\"空間中物件配置豐富\")\n",
    "    elif len(detections) > 4:\n",
    "        relationships.append(\"空間中有適度的物件配置\")\n",
    "    return '；'.join(relationships) + '。' if relationships else \"\"\n",
    "\n",
    "def generate_enhanced_caption(\n",
    "    image_path: str,\n",
    "    detections: List[Dict],\n",
    "    room_hint: Optional[str] = None,\n",
    "    knowledge_items: Optional[List[str]] = None,\n",
    "    *,\n",
    "    include_objects: bool = True,\n",
    "    include_spatial: bool = True,\n",
    "    include_room: bool = True,\n",
    "    include_knowledge: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    生成詳細描述；可用開關控制是否拼接「物件摘要/空間關係/房間推斷/知識補充」。\n",
    "    若要「只要敘述」，把四個 include_* 都設為 False。\n",
    "    \"\"\"\n",
    "    initialize_models()\n",
    "\n",
    "    # 生成多個不同角度的基礎描述\n",
    "    base_captions = []\n",
    "    prompts = [\n",
    "        \"Describe this indoor scene in detail, focusing on the people, furniture, and activities.\",\n",
    "        \"What is happening in this room? Describe the environment, objects, and any people present.\",\n",
    "        \"Provide a comprehensive description of this indoor space, including all visible elements.\"\n",
    "    ]\n",
    "    for prompt in prompts[:2]:\n",
    "        try:\n",
    "            cap = generate_base_caption(image_path, prompt)\n",
    "            if cap and len(cap) > 10:\n",
    "                base_captions.append(cap)\n",
    "        except Exception as e:\n",
    "            print(f\"生成描述時出錯: {e}\")\n",
    "            continue\n",
    "    if not base_captions:\n",
    "        base_captions = [generate_base_caption(image_path)]\n",
    "    primary_caption = max(base_captions, key=len) if base_captions else \"Indoor scene\"\n",
    "\n",
    "    # 翻譯為中文（純敘述基底）\n",
    "    zh_caption = translate_to_traditional_chinese(primary_caption)\n",
    "    description_parts = [zh_caption]  # 基底：只敘述\n",
    "\n",
    "    # 依開關決定是否附加其他說明\n",
    "    if include_objects:\n",
    "        object_desc = create_object_description(detections)\n",
    "        if object_desc:\n",
    "            description_parts.append(f\"偵測到的主要物件包括：{object_desc}\")\n",
    "    if include_spatial:\n",
    "        spatial_desc = analyze_spatial_relationships(detections)\n",
    "        if spatial_desc:\n",
    "            description_parts.append(f\"空間配置特徵：{spatial_desc}\")\n",
    "    if include_room and room_hint:\n",
    "        env_templates = ENVIRONMENT_TEMPLATES.get(room_hint, [f'{room_hint}環境'])\n",
    "        env_desc = env_templates[0] if env_templates else f'{room_hint}環境'\n",
    "        description_parts.append(f\"場景分析：此為{env_desc}。\")\n",
    "    if include_knowledge and knowledge_items:\n",
    "        kg_desc = '；'.join(knowledge_items)\n",
    "        description_parts.append(f\"知識圖譜補充：{kg_desc}。\")\n",
    "\n",
    "    final_description = ' '.join(description_parts)\n",
    "    if not final_description.endswith('。'):\n",
    "        final_description += '。'\n",
    "    return final_description\n",
    "\n",
    "def augment_with_knowledge_graph(caption: str, detections: List[Dict], knowledge_items: Optional[List[str]] = None) -> str:\n",
    "    \"\"\"預留與知識圖譜整合的接口\"\"\"\n",
    "    if not knowledge_items:\n",
    "        return caption\n",
    "    extra_knowledge = '；'.join(knowledge_items)\n",
    "    return f\"{caption} 知識圖譜增強：{extra_knowledge}。\"\n",
    "\n",
    "__all__ = [\n",
    "    'initialize_models',\n",
    "    'generate_enhanced_caption',\n",
    "    'infer_room_from_detections',\n",
    "    'augment_with_knowledge_graph'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549bdad",
   "metadata": {
    "id": "d549bdad"
   },
   "source": [
    "## 工具模組：`scripts/utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f99e64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5f99e64",
    "outputId": "2866b263-153d-4156-8921-757fe0214347"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/utils.py\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "_LABEL_ALIASES: Dict[str, str] = {\n",
    "    'people': 'person',\n",
    "    'men': 'person',\n",
    "    'man': 'person',\n",
    "    'women': 'person',\n",
    "    'woman': 'person',\n",
    "    'elderly person': 'elderly',\n",
    "    'old man': 'elderly',\n",
    "    'old woman': 'elderly',\n",
    "    'baby girl': 'baby',\n",
    "    'baby boy': 'baby',\n",
    "    'couch': 'sofa',\n",
    "    'arm chair': 'chair',\n",
    "    'armchair': 'chair',\n",
    "    'dining chair': 'chair',\n",
    "    'office chair': 'chair',\n",
    "    'wheel chair': 'chair',\n",
    "    'rocking chair': 'chair',\n",
    "    'coffee table': 'coffeetable',\n",
    "    'side table': 'coffeetable',\n",
    "    'end table': 'coffeetable',\n",
    "    'dining table': 'kitchentable',\n",
    "    'kitchen table': 'kitchentable',\n",
    "    'bedside table': 'nightstand',\n",
    "    'night stand': 'nightstand',\n",
    "    'television': 'tv',\n",
    "    'tv monitor': 'tv',\n",
    "    'flat screen tv': 'tv',\n",
    "    'monitor': 'cpuscreen',\n",
    "    'screen': 'cpuscreen',\n",
    "    'desktop computer': 'computer',\n",
    "    'laptop': 'computer',\n",
    "    'notebook computer': 'computer',\n",
    "    'desk lamp': 'tablelamp',\n",
    "    'table lamp': 'tablelamp',\n",
    "    'floor lamp': 'tablelamp',\n",
    "    'ceiling light': 'ceilinglamp',\n",
    "    'ceiling lamp': 'ceilinglamp',\n",
    "    'wall light': 'walllamp',\n",
    "    'wall lamp': 'walllamp',\n",
    "    'cupboard': 'cabinet',\n",
    "    'drawer': 'cabinet',\n",
    "    'closet drawer': 'cabinet',\n",
    "    'closet door': 'door',\n",
    "    'wardrobe': 'closet',\n",
    "    'kitchen cabinet': 'kitchencabinet',\n",
    "    'kitchen counter': 'kitchencounter',\n",
    "    'kitchen island': 'kitchencounter',\n",
    "    'countertop': 'kitchencounter',\n",
    "    'microwave oven': 'microwave',\n",
    "    'fridge': 'fridge',\n",
    "    'refrigerator': 'fridge',\n",
    "    'freezer': 'fridge',\n",
    "    'stovetop': 'stove',\n",
    "    'cooktop': 'stove',\n",
    "    'range': 'stove',\n",
    "    'trash can': 'garbagecan',\n",
    "    'trashcan': 'garbagecan',\n",
    "    'trash bin': 'garbagecan',\n",
    "    'garbage can': 'garbagecan',\n",
    "    'garbage bin': 'garbagecan',\n",
    "    'waste bin': 'garbagecan',\n",
    "    'remote': 'remotecontrol',\n",
    "    'remote control': 'remotecontrol',\n",
    "    'television remote': 'remotecontrol',\n",
    "    'picture frame': 'photoframe',\n",
    "    'picture': 'wallpictureframe',\n",
    "    'painting': 'wallpictureframe',\n",
    "    'book shelf': 'bookshelf',\n",
    "    'bookcase': 'bookshelf',\n",
    "    'wine glass': 'wineglass',\n",
    "    'glass': 'waterglass',\n",
    "    'coffee cup': 'mug',\n",
    "    'tea cup': 'mug',\n",
    "    'cup': 'mug',\n",
    "    'frying pan': 'fryingpan',\n",
    "    'sauce pan': 'cookingpot',\n",
    "    'cooking pan': 'fryingpan',\n",
    "    'cooking pot': 'cookingpot',\n",
    "    'wash basin': 'sink',\n",
    "    'basin': 'sink',\n",
    "    'bath tub': 'bathtub',\n",
    "    'toilet paper': 'toiletpaper',\n",
    "    'towel rail': 'towelrack',\n",
    "    'towel bar': 'towelrack',\n",
    "    'washing machine': 'washingmachine',\n",
    "    'wash machine': 'washingmachine',\n",
    "}\n",
    "\n",
    "def _collapse_label(label: str) -> str:\n",
    "    return ''.join(ch for ch in label if ch.isalnum())\n",
    "\n",
    "def normalize_label(label: str) -> str:\n",
    "    cleaned = (label or '').lower().strip()\n",
    "    if not cleaned:\n",
    "        return ''\n",
    "    cleaned = cleaned.replace('-', ' ')\n",
    "    cleaned = ' '.join(cleaned.split())\n",
    "    canonical = _LABEL_ALIASES.get(cleaned, cleaned)\n",
    "    collapsed = _collapse_label(canonical)\n",
    "    if not collapsed:\n",
    "        return ''\n",
    "    return collapsed\n",
    "\n",
    "def ensure_dir(path: Path) -> Path:\n",
    "    path = Path(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def save_txt(lines: List[str], filepath: Path) -> None:\n",
    "    filepath = Path(filepath)\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with filepath.open('w', encoding='utf-8') as f:\n",
    "        for line in lines:\n",
    "            f.write(str(line).rstrip() + '\\n')\n",
    "\n",
    "def format_timestamp(seconds: float) -> str:\n",
    "    seconds = int(seconds)\n",
    "    h = seconds // 3600\n",
    "    m = (seconds % 3600) // 60\n",
    "    s = seconds % 60\n",
    "    if h > 0:\n",
    "        return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "    return f\"{m:02d}:{s:02d}\"\n",
    "\n",
    "def format_detection_brief(timestamp: float, detections: List[Dict]) -> str:\n",
    "    t = format_timestamp(timestamp)\n",
    "    scores: Dict[str, float] = {}\n",
    "    for det in detections or []:\n",
    "        lbl = normalize_label(det.get('label') or det.get('raw_label', ''))\n",
    "        if not lbl:\n",
    "            continue\n",
    "        score = float(det.get('score', 0.0) or 0.0)\n",
    "        if lbl not in scores or score > scores[lbl]:\n",
    "            scores[lbl] = score\n",
    "    if not scores:\n",
    "        return f\"[{t}] 無偵測結果\"\n",
    "    ordered = sorted(scores.items(), key=lambda item: item[1], reverse=True)[:8]\n",
    "    brief = ', '.join(f\"{label}({value:.2f})\" for label, value in ordered)\n",
    "    return f\"[{t}] {brief}\"\n",
    "\n",
    "def create_visualization_summary(detections: List[Dict], max_items: int = 10) -> str:\n",
    "    if not detections:\n",
    "        return \"未偵測到物件\"\n",
    "    seen = set()\n",
    "    items = []\n",
    "    for det in detections:\n",
    "        lbl = normalize_label(det.get('label') or det.get('raw_label', ''))\n",
    "        if not lbl or lbl in seen:\n",
    "            continue\n",
    "        seen.add(lbl)\n",
    "        items.append(f\"{lbl}({float(det.get('score', 0.0) or 0.0):.2f})\")\n",
    "        if len(items) >= max_items:\n",
    "            break\n",
    "    return '、'.join(items) if items else \"未偵測到物件\"\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile scripts/caption_postprocess.py\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "import os\n",
    "\n",
    "from scripts.utils import normalize_label\n",
    "\n",
    "class CaptionPostProcessor:\n",
    "    def __init__(self, furniture_txt_path: str = 'furniture.txt', conf_th: float = 0.25):\n",
    "        self.furniture_txt_path = furniture_txt_path\n",
    "        self.conf_th = conf_th\n",
    "\n",
    "        self.prompt_prefixes = [\n",
    "            '描述環境、物體和在場的任何人',\n",
    "            '詳細描述這個室內場景',\n",
    "            '詳細描述這一室內場景',\n",
    "            '詳細描述這個室內場景, 以人、傢俱和活動為重點',\n",
    "            '詳細描述這個室內場景, 以人、傢俱和活動爲重點',\n",
    "            '詳細描述這個室內場景, 關注人們、傢俱和活動',\n",
    "            '詳細描述這個室內場景, 關注人羣、傢俱和活動',\n",
    "            '詳細描述這個室內場景,關注人羣、傢俱和活動',\n",
    "            '詳細描述這個室內場景,以人、傢俱和活動爲重點',\n",
    "        ]\n",
    "\n",
    "        self.object_aliases = {\n",
    "            'person': '人',\n",
    "            'elderly': '長者',\n",
    "            'baby': '嬰兒',\n",
    "            'bed': '床鋪',\n",
    "            'pillow': '枕頭',\n",
    "            'blanket': '毛毯',\n",
    "            'sheet': '床單',\n",
    "            'mattress': '床墊',\n",
    "            'nightstand': '床頭櫃',\n",
    "            'tablelamp': '檯燈',\n",
    "            'ceilinglamp': '天花板燈',\n",
    "            'walllamp': '壁燈',\n",
    "            'sofa': '沙發',\n",
    "            'chair': '椅子',\n",
    "            'coffeetable': '茶几',\n",
    "            'kitchentable': '餐桌',\n",
    "            'desk': '書桌',\n",
    "            'cabinet': '櫥櫃',\n",
    "            'kitchencabinet': '廚房櫃',\n",
    "            'kitchencounter': '流理台',\n",
    "            'bookshelf': '書架',\n",
    "            'wallshelf': '壁掛架',\n",
    "            'closet': '衣櫃',\n",
    "            'closetdrawer': '衣櫃抽屜',\n",
    "            'tvstand': '電視櫃',\n",
    "            'tv': '電視',\n",
    "            'cpuscreen': '螢幕',\n",
    "            'computer': '電腦',\n",
    "            'keyboard': '鍵盤',\n",
    "            'mouse': '滑鼠',\n",
    "            'printer': '印表機',\n",
    "            'speaker': '喇叭',\n",
    "            'amplifier': '擴大機',\n",
    "            'radio': '收音機',\n",
    "            'coffeemaker': '咖啡機',\n",
    "            'coffeepot': '咖啡壺',\n",
    "            'microwave': '微波爐',\n",
    "            'fridge': '冰箱',\n",
    "            'stove': '爐台',\n",
    "            'oven': '烤箱',\n",
    "            'fryingpan': '平底鍋',\n",
    "            'cookingpot': '湯鍋',\n",
    "            'dishwasher': '洗碗機',\n",
    "            'washingmachine': '洗衣機',\n",
    "            'sink': '水槽',\n",
    "            'faucet': '水龍頭',\n",
    "            'dishbowl': '碗',\n",
    "            'plate': '盤子',\n",
    "            'mug': '馬克杯',\n",
    "            'waterglass': '玻璃杯',\n",
    "            'wineglass': '紅酒杯',\n",
    "            'cutleryfork': '叉子',\n",
    "            'cutleryknife': '刀子',\n",
    "            'cuttingboard': '砧板',\n",
    "            'garbagecan': '垃圾桶',\n",
    "            'toaster': '烤麵包機',\n",
    "            'toilet': '馬桶',\n",
    "            'toiletpaper': '衛生紙',\n",
    "            'bathtub': '浴缸',\n",
    "            'shower': '淋浴設備',\n",
    "            'towel': '毛巾',\n",
    "            'towelrack': '毛巾架',\n",
    "            'mirror': '鏡子',\n",
    "            'door': '門',\n",
    "            'doorjamb': '門框',\n",
    "            'window': '窗戶',\n",
    "            'curtains': '窗簾',\n",
    "            'floor': '地板',\n",
    "            'wall': '牆面',\n",
    "            'ceiling': '天花板',\n",
    "            'rug': '地毯',\n",
    "            'plant': '植物',\n",
    "            'flower': '花朵',\n",
    "            'clock': '時鐘',\n",
    "            'photoframe': '相框',\n",
    "            'wallpictureframe': '壁掛畫',\n",
    "            'book': '書籍',\n",
    "            'notes': '筆記',\n",
    "            'magazine': '雜誌',\n",
    "            'paper': '紙張',\n",
    "            'folder': '文件夾',\n",
    "            'remotecontrol': '遙控器',\n",
    "            'lightswitch': '開關',\n",
    "            'powersocket': '插座',\n",
    "            'washingsponge': '海綿',\n",
    "            'barsoap': '肥皂',\n",
    "            'toothbrush': '牙刷',\n",
    "            'toothpaste': '牙膏',\n",
    "            'facecream': '護膚霜',\n",
    "            'deodorant': '除臭劑',\n",
    "            'hairproduct': '美髮產品',\n",
    "            'alcohol': '酒精',\n",
    "            'bottlewater': '礦泉水',\n",
    "            'milk': '牛奶',\n",
    "            'juice': '果汁',\n",
    "            'wine': '紅酒',\n",
    "            'apple': '蘋果',\n",
    "            'bananas': '香蕉',\n",
    "            'bellpepper': '甜椒',\n",
    "            'carrot': '胡蘿蔔',\n",
    "            'salmon': '鮭魚',\n",
    "            'chicken': '雞肉',\n",
    "            'mincedmeat': '絞肉',\n",
    "            'breadslice': '麵包片',\n",
    "            'cereal': '麥片',\n",
    "            'crackers': '餅乾',\n",
    "            'cupcake': '杯子蛋糕',\n",
    "            'pancake': '鬆餅',\n",
    "            'pie': '派',\n",
    "            'pudding': '布丁',\n",
    "            'creamybuns': '奶油麵包',\n",
    "            'cat': '貓',\n",
    "            'toy': '玩具',\n",
    "            'boardgame': '桌遊',\n",
    "            'guitar': '吉他',\n",
    "        }\n",
    "\n",
    "        self.furniture_set = {\n",
    "            '床鋪', '床頭櫃', '椅子', '沙發', '茶几', '餐桌', '書桌', '櫥櫃', '廚房櫃', '流理台',\n",
    "            '書架', '壁掛架', '衣櫃', '衣櫃抽屜', '電視櫃'\n",
    "        }\n",
    "\n",
    "        self.room_rules = [\n",
    "            ('廚房', {'流理台', '廚房櫃', '咖啡機', '爐台', '微波爐', '冰箱', '湯鍋', '平底鍋', '砧板'}),\n",
    "            ('臥室', {'床鋪', '枕頭', '床頭櫃', '衣櫃', '書桌'}),\n",
    "            ('客廳', {'沙發', '茶几', '電視', '電視櫃', '遙控器', '地毯'}),\n",
    "            ('浴室', {'馬桶', '浴缸', '水槽', '毛巾', '毛巾架', '鏡子'}),\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(self.furniture_txt_path):\n",
    "                os.remove(self.furniture_txt_path)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    def process(self, ts_hhmm: str, det_items: List[Dict[str, Any]], raw_caption: str) -> str:\n",
    "        categories = self._dedupe_by_category(det_items, self.conf_th)\n",
    "        self._append_furniture(ts_hhmm, categories)\n",
    "\n",
    "        caption = self._clean_text(raw_caption or '')\n",
    "        if not caption:\n",
    "            has_person = self._has_person(categories, raw_caption or '')\n",
    "            room_hint = self._guess_room(categories)\n",
    "            caption = self._compose_neutral_sentence(room_hint, categories, has_person)\n",
    "\n",
    "        objects_str = self._format_objects(categories)\n",
    "        return f\"[{ts_hhmm}] {caption} 偵測到的主要物件包括：{objects_str}。\"\n",
    "\n",
    "    def _zh_label(self, label: str, raw_label: str = '') -> str:\n",
    "        key = normalize_label(label or raw_label)\n",
    "        if key in self.object_aliases:\n",
    "            return self.object_aliases[key]\n",
    "        candidate = raw_label.strip() or label.strip()\n",
    "        candidate = re.sub(r'[^\\w一-龥]', '', candidate)\n",
    "        return candidate\n",
    "\n",
    "    def _auto_category(self, canonical: str, zh_name: str) -> str:\n",
    "        furniture_keys = {\n",
    "            'bed', 'nightstand', 'sofa', 'chair', 'coffeetable', 'kitchentable', 'desk',\n",
    "            'cabinet', 'kitchencabinet', 'kitchencounter', 'bookshelf', 'wallshelf', 'closet',\n",
    "            'closetdrawer', 'tvstand'\n",
    "        }\n",
    "        appliance_keys = {\n",
    "            'tv', 'cpuscreen', 'computer', 'printer', 'speaker', 'amplifier', 'radio',\n",
    "            'coffeemaker', 'microwave', 'fridge', 'stove', 'oven', 'dishwasher',\n",
    "            'washingmachine', 'toaster', 'tablelamp', 'ceilinglamp', 'walllamp'\n",
    "        }\n",
    "        if canonical in furniture_keys:\n",
    "            return '家具'\n",
    "        if canonical in appliance_keys:\n",
    "            return '電器'\n",
    "        if zh_name in self.furniture_set:\n",
    "            return '家具'\n",
    "        return '其他物件'\n",
    "\n",
    "    def _dedupe_by_category(self, det_items: List[Dict[str, Any]], conf_th: float) -> Dict[str, List[str]]:\n",
    "        output = {'家具': set(), '電器': set(), '其他物件': set()}\n",
    "        for det in det_items or []:\n",
    "            score = float(det.get('score', 0.0) or 0.0)\n",
    "            if score < conf_th:\n",
    "                continue\n",
    "            raw_label = det.get('raw_label', '') or det.get('label', '')\n",
    "            canonical = normalize_label(raw_label)\n",
    "            if not canonical:\n",
    "                continue\n",
    "            zh_name = self._zh_label(canonical, raw_label)\n",
    "            if not zh_name:\n",
    "                continue\n",
    "            category = det.get('category')\n",
    "            if not category:\n",
    "                category = self._auto_category(canonical, zh_name)\n",
    "            if category not in output:\n",
    "                category = '其他物件'\n",
    "            output[category].add(zh_name)\n",
    "        return {key: sorted(values) for key, values in output.items() if values}\n",
    "\n",
    "    def _append_furniture(self, ts_hhmm: str, categories: Dict[str, List[str]]) -> None:\n",
    "        furniture_names = [name for name in categories.get('家具', []) if name in self.furniture_set]\n",
    "        line = f\"[{ts_hhmm}] 家具：\" + ('、'.join(furniture_names) if furniture_names else '無')\n",
    "        try:\n",
    "            with open(self.furniture_txt_path, 'a', encoding='utf-8') as fp:\n",
    "                fp.write(line + '\\n')\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        cleaned = text\n",
    "        for prefix in self.prompt_prefixes:\n",
    "            cleaned = cleaned.replace(prefix, '')\n",
    "        cleaned = ' '.join(token for token in cleaned.split() if not token.startswith('##'))\n",
    "        cleaned = cleaned.replace('，,', '，').replace(',,', ',').replace('..', '.')\n",
    "        return cleaned.strip(' 、。,.；;')\n",
    "\n",
    "    def _has_person(self, categories: Dict[str, List[str]], caption: str) -> bool:\n",
    "        all_words = ''.join(sum(categories.values(), [])) + caption\n",
    "        return '人' in all_words or 'person' in all_words.lower()\n",
    "\n",
    "    def _guess_room(self, categories: Dict[str, List[str]]) -> str:\n",
    "        bag = set(sum(categories.values(), []))\n",
    "        for room, triggers in self.room_rules:\n",
    "            if bag & triggers:\n",
    "                return room\n",
    "        return ''\n",
    "\n",
    "    def _compose_neutral_sentence(self, room_hint: str, categories: Dict[str, List[str]], has_person: bool) -> str:\n",
    "        room_text = f'在{room_hint}' if room_hint else '在室內'\n",
    "        furniture = '、'.join(categories.get('家具', [])[:3])\n",
    "        appliances = '、'.join(categories.get('電器', [])[:2])\n",
    "        others = '、'.join(categories.get('其他物件', [])[:2])\n",
    "        obj_text = '、'.join(filter(None, [furniture, appliances, others]))\n",
    "        if has_person:\n",
    "            if obj_text:\n",
    "                return f'{room_text}可見有人，周圍有{obj_text}。'\n",
    "            return f'{room_text}可見有人。'\n",
    "        if obj_text:\n",
    "            return f'{room_text}可見{obj_text}。'\n",
    "        return f'{room_text}環境整潔，物件稀疏。'\n",
    "\n",
    "    def _format_objects(self, categories: Dict[str, List[str]]) -> str:\n",
    "        parts = []\n",
    "        for name in ('家具', '電器', '其他物件'):\n",
    "            entries = categories.get(name, [])\n",
    "            if entries:\n",
    "                parts.append(f\"{name}：\" + '、'.join(entries))\n",
    "        return '；'.join(parts) if parts else '無明顯物件'\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmJqE_EcbFZy",
    "outputId": "17ae5e48-1b34-4a74-db37-3d52ebf22527"
   },
   "id": "kmJqE_EcbFZy",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing scripts/caption_postprocess.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f323f",
   "metadata": {
    "id": "3e0f323f"
   },
   "source": [
    "## 主程式：`main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45bdc47b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45bdc47b",
    "outputId": "a3a5bd66-1ba1-41a6-ee0e-b52fcb495fda"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scripts.extract_frames import extract_frames\n",
    "from scripts.object_detector import setup_grounding_dino, detect_objects, summarize_detections, analyze_scene_context, DEFAULT_PROMPT\n",
    "from scripts.generate_caption import initialize_models, generate_enhanced_caption, infer_room_from_detections\n",
    "from scripts.utils import ensure_dir, save_txt, format_detection_brief, format_timestamp, create_visualization_summary\n",
    "\n",
    "VIDEO_EXTS = {'.mp4', '.mov', '.mkv', '.avi', '.webm'}\n",
    "\n",
    "def iter_videos(targets: Iterable[Path]):\n",
    "    \"\"\"遍歷所有影片檔案\"\"\"\n",
    "    for target in targets:\n",
    "        target = Path(target)\n",
    "        if target.is_file() and target.suffix.lower() in VIDEO_EXTS:\n",
    "            yield target\n",
    "        elif target.is_dir():\n",
    "            for path in sorted(target.rglob('*')):\n",
    "                if path.suffix.lower() in VIDEO_EXTS:\n",
    "                    yield path\n",
    "\n",
    "def process_video(\n",
    "    video_path: Path,\n",
    "    output_root: Path,\n",
    "    fps_sample: float = 1.0,\n",
    "    text_prompt: str = DEFAULT_PROMPT,\n",
    "    show_detection_images: bool = True,\n",
    "    max_preview_images: int = 5\n",
    ") -> Path:\n",
    "    \"\"\"處理單一影片\"\"\"\n",
    "    video_path = Path(video_path)\n",
    "    video_output = ensure_dir(output_root / video_path.stem)\n",
    "    frames_dir = ensure_dir(video_output / 'frames')\n",
    "    detections_dir = ensure_dir(video_output / 'detections')\n",
    "\n",
    "    print(f'\\n=== 開始處理影片：{video_path.name} ===')\n",
    "    print('正在提取影格...')\n",
    "    frame_entries, native_fps = extract_frames(str(video_path), str(frames_dir), target_fps=fps_sample)\n",
    "    if not frame_entries:\n",
    "        raise RuntimeError(f'影片 {video_path} 未擷取到任何影格，請確認檔案是否為有效影片。')\n",
    "    print(f'成功提取 {len(frame_entries)} 個影格，原始FPS: {native_fps:.2f}')\n",
    "\n",
    "    subtitle_lines = []\n",
    "    detection_lines = []\n",
    "    preview_count = 0\n",
    "\n",
    "    for idx, (frame_path, timestamp) in enumerate(tqdm(frame_entries, desc=f'分析 {video_path.name}')):\n",
    "        try:\n",
    "            detections, annotated_image = detect_objects(\n",
    "                frame_path,\n",
    "                text_prompt=text_prompt,\n",
    "                visualize=True\n",
    "            )\n",
    "            if annotated_image is not None:\n",
    "                annotated_path = detections_dir / f'{Path(frame_path).stem}_detection.jpg'\n",
    "                annotated_image.save(annotated_path)\n",
    "                if show_detection_images and preview_count < max_preview_images:\n",
    "                    print(f'\\n第 {idx+1} 個影格偵測結果：')\n",
    "                    vis_summary = create_visualization_summary(detections, len(detections))\n",
    "                    print(vis_summary)\n",
    "                    print(f'高信心度物件：{summarize_detections(detections, top_k=5)}')\n",
    "                    preview_count += 1\n",
    "\n",
    "            scene_context = analyze_scene_context(detections)\n",
    "            room_hint = infer_room_from_detections(detections)\n",
    "\n",
    "            # 重要：字幕只留「純敘述」，關閉所有附加片段\n",
    "            pure_caption = generate_enhanced_caption(\n",
    "                frame_path,\n",
    "                detections,\n",
    "                room_hint=room_hint,\n",
    "                include_objects=False,\n",
    "                include_spatial=False,\n",
    "                include_room=False,\n",
    "                include_knowledge=False,\n",
    "            )\n",
    "            time_str = format_timestamp(timestamp)\n",
    "            subtitle_lines.append(f'[{time_str}] {pure_caption}')\n",
    "\n",
    "            # 偵測摘要（保持原樣，不動）\n",
    "            detection_summary = format_detection_brief(timestamp, detections)\n",
    "            if scene_context['person_count'] > 0:\n",
    "                detection_summary += f' | 人數:{scene_context[\"person_count\"]}'\n",
    "            if room_hint:\n",
    "                detection_summary += f' | 房間:{room_hint}'\n",
    "            detection_lines.append(detection_summary)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'處理第 {idx+1} 個影格時發生錯誤: {e}')\n",
    "            error_msg = f'[{format_timestamp(timestamp)}] 處理錯誤: {str(e)}'\n",
    "            subtitle_lines.append(error_msg)\n",
    "            detection_lines.append(error_msg)\n",
    "\n",
    "    subs_path = video_output / f'{video_path.stem}_captions.txt'\n",
    "    det_path = video_output / f'{video_path.stem}_detections.txt'\n",
    "    save_txt(subtitle_lines, subs_path)\n",
    "    save_txt(detection_lines, det_path)\n",
    "\n",
    "    report_lines = [\n",
    "        f'影片處理報告 - {video_path.name}',\n",
    "        '=' * 50,\n",
    "        f'原始FPS: {native_fps:.2f}',\n",
    "        f'取樣FPS: {fps_sample}',\n",
    "        f'處理影格數: {len(frame_entries)}',\n",
    "        f'影片總時長: {format_timestamp(frame_entries[-1][1])}' if frame_entries else '無',\n",
    "        f'輸出檔案:',\n",
    "        f'  - 詳細字幕: {subs_path.name}',\n",
    "        f'  - 偵測摘要: {det_path.name}',\n",
    "        f'  - 標註圖像目錄: {detections_dir.name}/',\n",
    "        f'  - 原始影格目錄: {frames_dir.name}/'\n",
    "    ]\n",
    "    report_path = video_output / f'{video_path.stem}_report.txt'\n",
    "    save_txt(report_lines, report_path)\n",
    "\n",
    "    print(f'\\n處理完成！')\n",
    "    print(f'詳細字幕檔: {subs_path}')\n",
    "    print(f'偵測摘要檔: {det_path}')\n",
    "    print(f'處理報告: {report_path}')\n",
    "    print(f'標註圖像: {detections_dir}/')\n",
    "    return subs_path\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"主程式入口\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='增強版影片分析系統 - Grounding DINO + BLIP')\n",
    "    parser.add_argument('--video', help='指定單一影片路徑')\n",
    "    parser.add_argument('--dir', help='處理資料夾下的所有影片')\n",
    "    parser.add_argument('--fps', type=float, default=1.0, help='取樣頻率(每秒擷取影格數)')\n",
    "    parser.add_argument('--output-dir', default='outputs', help='輸出根目錄')\n",
    "    parser.add_argument('--prompt', default=DEFAULT_PROMPT, help='物件偵測提示詞')\n",
    "    parser.add_argument('--no-preview', action='store_true', help='不顯示偵測預覽圖像')\n",
    "    parser.add_argument('--max-preview', type=int, default=5, help='最多顯示幾張預覽圖像')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not args.video and not args.dir:\n",
    "        parser.error('請至少指定 --video 或 --dir 其中之一。')\n",
    "\n",
    "    print('正在初始化模型...')\n",
    "    setup_grounding_dino()\n",
    "    initialize_models()\n",
    "    print('所有模型已準備完成。')\n",
    "\n",
    "    targets = []\n",
    "    if args.video:\n",
    "        targets.append(Path(args.video))\n",
    "    if args.dir:\n",
    "        targets.append(Path(args.dir))\n",
    "    output_root = ensure_dir(args.output_dir)\n",
    "\n",
    "    processed_count = 0\n",
    "    for video in iter_videos(targets):\n",
    "        try:\n",
    "            process_video(\n",
    "                video,\n",
    "                output_root,\n",
    "                fps_sample=args.fps,\n",
    "                text_prompt=args.prompt,\n",
    "                show_detection_images=not args.no_preview,\n",
    "                max_preview_images=args.max_preview\n",
    "            )\n",
    "            processed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f'處理影片 {video} 時發生錯誤: {e}')\n",
    "            continue\n",
    "\n",
    "    print('\\n=== 所有處理完成 ===')\n",
    "    print(f'成功處理 {processed_count} 個影片檔案')\n",
    "    print(f'輸出目錄: {output_root}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2d9f2",
   "metadata": {
    "id": "1cd2d9f2"
   },
   "source": [
    "## 執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce777e89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce777e89",
    "outputId": "291b0ac7-3fa2-47fa-8cdd-fd84c7cd1bb3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2025-09-21 15:45:41.428557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758469541.449776    2472 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758469541.456100    2472 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758469541.471929    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758469541.471960    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758469541.471963    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758469541.471969    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-21 15:45:41.476828: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "正在初始化模型...\n",
      "正在載入 Grounding DINO 模型...\n",
      "Fetching 1 files: 100% 1/1 [00:00<00:00, 2685.21it/s]\n",
      "Fetching 1 files: 100% 1/1 [00:00<00:00, 14513.16it/s]\n",
      "Grounding DINO 模型已載入至 cuda\n",
      "正在載入 BLIP 模型...\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Fetching 1 files: 100% 1/1 [00:00<00:00, 3057.07it/s]\n",
      "BLIP 模型已載入至 cuda\n",
      "正在載入翻譯模型...\n",
      "Device set to use cuda:0\n",
      "翻譯模型已載入\n",
      "所有模型已準備完成。\n",
      "\n",
      "=== 開始處理影片：Cook carrot1_1.mp4 ===\n",
      "正在提取影格...\n",
      "已提取 65 個影格，原始FPS: 30.00\n",
      "成功提取 65 個影格，原始FPS: 30.00\n",
      "分析 Cook carrot1_1.mp4:   0% 0/65 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/models/grounding_dino/processing_grounding_dino.py:94: FutureWarning: The key `labels` is will return integer ids in `GroundingDinoProcessor.post_process_grounded_object_detection` output since v4.51.0. Use `text_labels` instead to retrieve string object names.\n",
      "  warnings.warn(self.message, FutureWarning)\n",
      "\n",
      "第 1 個影格偵測結果：\n",
      "tv monitor(0.39)、table desk table table table desk(0.34)、fork rug(0.32)、cabinet pan(0.25)\n",
      "高信心度物件：tv monitor(0.39), table desk table table table desk(0.34), fork rug(0.32), cabinet pan(0.25)\n",
      "分析 Cook carrot1_1.mp4:   2% 1/65 [00:03<03:26,  3.23s/it]\n",
      "第 2 個影格偵測結果：\n",
      "tv monitor(0.40)、table desk table table table desk(0.34)、sink knife fork rug(0.33)、cabinet(0.25)\n",
      "高信心度物件：tv monitor(0.40), table desk table table table desk(0.34), sink knife fork rug(0.33), cabinet(0.25)\n",
      "分析 Cook carrot1_1.mp4:   3% 2/65 [00:05<02:42,  2.58s/it]\n",
      "第 3 個影格偵測結果：\n",
      "tv monitor(0.39)、sink knife fork rug(0.33)、table desk table table table desk(0.32)、cabinet(0.26)\n",
      "高信心度物件：tv monitor(0.39), sink knife fork rug(0.33), table desk table table table desk(0.32), cabinet(0.26)\n",
      "分析 Cook carrot1_1.mp4:   5% 3/65 [00:07<02:15,  2.18s/it]\n",
      "第 4 個影格偵測結果：\n",
      "tv monitor(0.38)、sink knife fork rug(0.33)、table desk table table table desk(0.32)、cabinet(0.26)\n",
      "高信心度物件：tv monitor(0.38), sink knife fork rug(0.33), table desk table table table desk(0.32), cabinet(0.26)\n",
      "分析 Cook carrot1_1.mp4:   6% 4/65 [00:08<02:02,  2.01s/it]\n",
      "第 5 個影格偵測結果：\n",
      "chair chair chair(0.43)\n",
      "高信心度物件：chair chair chair(0.43)\n",
      "分析 Cook carrot1_1.mp4:  15% 10/65 [00:18<01:32,  1.68s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "分析 Cook carrot1_1.mp4: 100% 65/65 [01:52<00:00,  1.73s/it]\n",
      "\n",
      "處理完成！\n",
      "詳細字幕檔: outputs/Cook carrot1_1/Cook carrot1_1_captions.txt\n",
      "偵測摘要檔: outputs/Cook carrot1_1/Cook carrot1_1_detections.txt\n",
      "處理報告: outputs/Cook carrot1_1/Cook carrot1_1_report.txt\n",
      "標註圖像: outputs/Cook carrot1_1/detections/\n",
      "\n",
      "=== 開始處理影片：Cook fried bread4_1.mp4 ===\n",
      "正在提取影格...\n",
      "已提取 65 個影格，原始FPS: 30.00\n",
      "成功提取 65 個影格，原始FPS: 30.00\n",
      "分析 Cook fried bread4_1.mp4:   0% 0/65 [00:00<?, ?it/s]\n",
      "第 1 個影格偵測結果：\n",
      "chair chair chair(0.38)、desk desk(0.27)\n",
      "高信心度物件：chair chair chair(0.38), desk desk(0.27)\n",
      "分析 Cook fried bread4_1.mp4:   2% 1/65 [00:01<01:41,  1.59s/it]\n",
      "第 2 個影格偵測結果：\n",
      "desk desk(0.27)\n",
      "高信心度物件：desk desk(0.27)\n",
      "分析 Cook fried bread4_1.mp4:   3% 2/65 [00:03<01:38,  1.56s/it]\n",
      "第 3 個影格偵測結果：\n",
      "chair chair chair(0.42)、desk desk(0.27)\n",
      "高信心度物件：chair chair chair(0.42), desk desk(0.27)\n",
      "分析 Cook fried bread4_1.mp4:   5% 3/65 [00:04<01:37,  1.58s/it]\n",
      "第 4 個影格偵測結果：\n",
      "chair chair chair(0.42)、desk desk(0.26)\n",
      "高信心度物件：chair chair chair(0.42), desk desk(0.26)\n",
      "分析 Cook fried bread4_1.mp4:   6% 4/65 [00:06<01:41,  1.66s/it]\n",
      "第 5 個影格偵測結果：\n",
      "chair chair chair(0.42)\n",
      "高信心度物件：chair chair chair(0.42)\n",
      "分析 Cook fried bread4_1.mp4: 100% 65/65 [01:53<00:00,  1.75s/it]\n",
      "\n",
      "處理完成！\n",
      "詳細字幕檔: outputs/Cook fried bread4_1/Cook fried bread4_1_captions.txt\n",
      "偵測摘要檔: outputs/Cook fried bread4_1/Cook fried bread4_1_detections.txt\n",
      "處理報告: outputs/Cook fried bread4_1/Cook fried bread4_1_report.txt\n",
      "標註圖像: outputs/Cook fried bread4_1/detections/\n",
      "\n",
      "=== 開始處理影片：Cook potato using microwave1_4.mp4 ===\n",
      "正在提取影格...\n",
      "已提取 76 個影格，原始FPS: 30.00\n",
      "成功提取 76 個影格，原始FPS: 30.00\n",
      "分析 Cook potato using microwave1_4.mp4:   0% 0/76 [00:00<?, ?it/s]\n",
      "第 1 個影格偵測結果：\n",
      "chair chair chair(0.36)、table table table table(0.29)、rug(0.27)、cabinet(0.27)\n",
      "高信心度物件：chair chair chair(0.36), table table table table(0.29), rug(0.27), cabinet(0.27)\n",
      "分析 Cook potato using microwave1_4.mp4:   1% 1/76 [00:01<02:00,  1.61s/it]\n",
      "第 2 個影格偵測結果：\n",
      "chair chair chair(0.37)、fork rug(0.29)、table table table table(0.29)、cabinet(0.29)、desk desk(0.29)、monitor(0.27)\n",
      "高信心度物件：chair chair chair(0.37), fork rug(0.29), table table table table(0.29), cabinet(0.29), desk desk(0.29)\n",
      "分析 Cook potato using microwave1_4.mp4:  16% 12/76 [00:20<01:37,  1.52s/it]\n",
      "第 13 個影格偵測結果：\n",
      "table table table table(0.26)\n",
      "高信心度物件：table table table table(0.26)\n",
      "分析 Cook potato using microwave1_4.mp4:  17% 13/76 [00:21<01:35,  1.52s/it]\n",
      "第 14 個影格偵測結果：\n",
      "table table table table(0.25)\n",
      "高信心度物件：table table table table(0.25)\n",
      "分析 Cook potato using microwave1_4.mp4: 100% 76/76 [02:08<00:00,  1.69s/it]\n",
      "\n",
      "處理完成！\n",
      "詳細字幕檔: outputs/Cook potato using microwave1_4/Cook potato using microwave1_4_captions.txt\n",
      "偵測摘要檔: outputs/Cook potato using microwave1_4/Cook potato using microwave1_4_detections.txt\n",
      "處理報告: outputs/Cook potato using microwave1_4/Cook potato using microwave1_4_report.txt\n",
      "標註圖像: outputs/Cook potato using microwave1_4/detections/\n",
      "\n",
      "=== 所有處理完成 ===\n",
      "成功處理 3 個影片檔案\n",
      "輸出目錄: outputs\n"
     ]
    }
   ],
   "source": [
    "# 單支影片\n",
    "# !python main.py --video data/videos/你的影片.mp4 --fps 2 --output-dir outputs\n",
    "\n",
    "# 批次處理資料夾\n",
    "!python main.py --dir data/videos --fps 1 --output-dir outputs"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import IPython.display as display\n",
    "\n",
    "# 執行完這段會呼叫前端 JS，讓 Colab 斷線\n",
    "# display.display(display.Javascript('google.colab.kernel.disconnect()'))\n"
   ],
   "metadata": {
    "id": "hWTLmq-ly1s8"
   },
   "id": "hWTLmq-ly1s8",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "51ecce7a",
   "metadata": {
    "id": "51ecce7a"
   },
   "source": [
    "## 可調參數與修改位置導覽（完整標示）\n",
    "- 修改偵測提示詞：`main.py` 的 `--prompt` 參數或 `scripts/object_detector.py` 的 `DEFAULT_PROMPT`。\n",
    "- 偵測信心閾值與回傳數量：`scripts/object_detector.py` 的 `detect_objects(..., box_threshold=0.25, top_k=15)`。\n",
    "- 影格取樣頻率：執行參數 `--fps`；或在 `scripts/extract_frames.py` 的 `target_fps` 預設值。\n",
    "- 翻譯與中文轉換：`scripts/generate_caption.py` 的 `initialize_models()` 使用 `Helsinki-NLP/opus-mt-en-zh` 及 `OpenCC('s2t')`。\n",
    "- 房間推斷關鍵詞：`scripts/generate_caption.py` 中的 `ROOM_KEYWORDS` 字典。\n",
    "- 環境描述模板：`scripts/generate_caption.py` 的 `ENVIRONMENT_TEMPLATES`。\n",
    "- 物件中英對照：`scripts/generate_caption.py` 的 `OBJECT_TRANSLATIONS`。\n",
    "- 文字輸出檔名與摘要邏輯：`scripts/utils.py` 的 `save_txt`, `format_detection_brief`, `format_timestamp`。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}